{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772a5e16",
   "metadata": {},
   "source": [
    "## Проект для Интернет-магазина с BERT\n",
    "\n",
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Наша задача — обучить модель, которая будет классифицировать комментарии как **токсичные (1)** или **нетоксичные (0)**.  \n",
    "\n",
    "**Целевая метрика**: F1 ≥ 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dc4f10",
   "metadata": {},
   "source": [
    "## План проекта (расширенный с BERT):\n",
    "\n",
    "**Цель:**  \n",
    "Построить модель, которая автоматически определяет токсичность комментариев пользователей для платформы Викишоп. Это позволит модерировать контент и поддерживать здоровую коммуникацию на платформе.\n",
    "\n",
    "---\n",
    "\n",
    "Этапы проекта:\n",
    "\n",
    "1. **Загрузка и предварительная подготовка данных**\n",
    "   - Импорт библиотек\n",
    "   - Загрузка и первичный анализ данных\n",
    "   - Проверка на пропуски, дубликаты, баланс классов\n",
    "\n",
    "2. **Очистка текста**\n",
    "   - Приведение к нижнему регистру\n",
    "   - Удаление лишних символов, HTML-тегов, стоп-слов и др.\n",
    "\n",
    "3. **Базовое моделирование**\n",
    "   - Векторизация текста с помощью `TfidfVectorizer`\n",
    "   - Обучение моделей: `LogisticRegression`, `LinearSVC`\n",
    "   - Подбор гиперпараметров с помощью `GridSearchCV`\n",
    "   - Оценка качества моделей с использованием F1-меры\n",
    "\n",
    "4. **Дообучение BERT (fine-tuning)**\n",
    "   - Использование предобученной модели `bert-base-multilingual-cased`\n",
    "   - Создание кастомного Dataset и DataLoader\n",
    "   - Fine-tuning на части обучающей выборки\n",
    "   - Оценка метрики F1 на валидационной выборке\n",
    "\n",
    "5. **Сравнение моделей**\n",
    "   - Сравнение F1-метрик базовых моделей и BERT\n",
    "   - Анализ производительности (время, ресурсы)\n",
    "   - Интерпретация результатов\n",
    "\n",
    "6. **Выводы**\n",
    "   - Обоснование выбора финальной модели\n",
    "   - Рекомендации по внедрению и возможному масштабированию\n",
    "\n",
    "---\n",
    "\n",
    "**Метрика качества:**  \n",
    "Основная метрика — F1-мера (взвешенное среднее между precision и recall), подходящая для несбалансированных классов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49693b4",
   "metadata": {},
   "source": [
    "## Импорты\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07a2700f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/dmitrysergeenko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/dmitrysergeenko/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dmitrysergeenko/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Базовые библиотеки\n",
    "import re\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Модели и метрики\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    StratifiedKFold,\n",
    "    StratifiedShuffleSplit\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Transformers и PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertModel,\n",
    "    BertForSequenceClassification,\n",
    "    AdamW,\n",
    "    get_scheduler\n",
    ")\n",
    "\n",
    "# Отключаем предупреждения\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0768bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n",
      "\n",
      "Распределение классов:\n",
      "toxic\n",
      "0    143106\n",
      "1     16186\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "df = pd.read_csv('/Users/dmitrysergeenko/Downloads/Яндекс.Практикум/Проекты на зачет/BERT. Векторизация текста/toxic_comments.csv')\n",
    "\n",
    "df.info()\n",
    "\n",
    "# Просмотр первых 5 строк\n",
    "df.head()\n",
    "\n",
    "# Распределение по классам (0 — нетоксичный, 1 — токсичный)\n",
    "print(\"\\nРаспределение классов:\")\n",
    "print(df['toxic'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf454c7a",
   "metadata": {},
   "source": [
    "В датасете содержится 159 292 комментария, каждый из которых размечен по признаку токсичности:\n",
    "\n",
    "Столбец text содержит текст комментария.\n",
    "\n",
    "Целевой признак toxic принимает значение 1 для токсичных комментариев и 0 для нетоксичных.\n",
    "\n",
    "Распределение классов несбалансированное:\n",
    "\n",
    "Нетоксичных комментариев — 143 106 (≈ 89.8%)\n",
    "\n",
    "Токсичных — 16 186 (≈ 10.2%)\n",
    "\n",
    "Также обнаружен лишний столбец Unnamed: 0, который является индексом и не несёт полезной информации - он будет удалён на этапе подготовки данных.\n",
    "\n",
    "При обучении моделей будем учитывать несбалансированность классов: F1-мера будет использоваться как основная метрика качества, поскольку она сбалансировано учитывает и полноту, и точность при работе с неравными классами.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "716b269e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Удалим лишнюю колонку\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Просмотрим первые 5 строк после удаления \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebdf152",
   "metadata": {},
   "source": [
    "Вывод: лишний столбец успешно удален."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f43cd1",
   "metadata": {},
   "source": [
    "Очистим текст (удалим спецсимволы и приведём к нижнему регистру)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "867fc5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Очистим текст\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()                             # приведение к нижнему регистру\n",
    "    text = re.sub(r'\\n+', ' ', text)                # замена переносов на пробел\n",
    "    text = re.sub(r'http\\S+', '', text)             # удаление URL\n",
    "    text = re.sub(r'<.*?>', '', text)               # удаление HTML\n",
    "    text = re.sub(r'@\\w+', '', text)                # удаление @mention\n",
    "    text = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s]', '', text)  # удаление знаков препинания\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()        # удаление лишних пробелов\n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f62d46",
   "metadata": {},
   "source": [
    "## Вариант решения без BERT\n",
    "\n",
    "Разделим на обучающую и тестовую выборки\n",
    "\n",
    "Применим TfidfVectorizer\n",
    "\n",
    "Обучим LogisticRegression\n",
    "\n",
    "Посчитаем F1-метрику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c1873b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на валидации: 0.678\n",
      "F1 на тесте: 0.689\n"
     ]
    }
   ],
   "source": [
    "# 1. Делим на train+val и test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    df['clean_text'], df['toxic'], test_size=0.2, random_state=42, stratify=df['toxic'])\n",
    "\n",
    "# 2. Делим X_temp на train и val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "# 3. TF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.9, min_df=5)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# 4. Обучение на train, настройка по val\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 5. Оценка на val\n",
    "val_pred = model.predict(X_val_tfidf)\n",
    "val_f1 = f1_score(y_val, val_pred)\n",
    "print(f\"F1 на валидации: {val_f1:.3f}\")\n",
    "\n",
    "# 6. Финальная оценка на test\n",
    "test_pred = model.predict(X_test_tfidf)\n",
    "test_f1 = f1_score(y_test, test_pred)\n",
    "print(f\"F1 на тесте: {test_f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad3dc76",
   "metadata": {},
   "source": [
    "Промежуточный вывод:\n",
    "\n",
    "Для классификации токсичных комментариев был реализован классический подход машинного обучения (модель без BERT):\n",
    "\n",
    "Тексты были преобразованы в числовые векторы с помощью метода TF-IDF.\n",
    "\n",
    "Была обучена модель логистической регрессии.\n",
    "\n",
    "Для оценки использовалась F1-мера на тестовой выборке.\n",
    "\n",
    "Результат:\n",
    "\n",
    "F1-мера на тесте = 0.689\n",
    "\n",
    "Модель пока не достигает требуемого уровня качества. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680a7de4",
   "metadata": {},
   "source": [
    "\n",
    "Доработаем классический ML-подход чтобы достичь метрики по ТЗ включающий три модели:\n",
    "\n",
    "LogisticRegression\n",
    "\n",
    "LinearSVC\n",
    "\n",
    "\n",
    "- Расширим настройки TF-IDF (настроем параметры TfidfVectorizer)\n",
    "- Используем пайплайн\n",
    "- Подберем наилучшую модель с оптимальными параметрами по F1-метрике.\n",
    "- Учтем несбалансированность классов (повысим чувствительность к меньшинству -токсичные комментарии)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e6ecb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] END clf=LogisticRegression(class_weight='balanced', max_iter=1000), clf__C=1.0; total time=  42.1s\n",
      "[CV] END clf=LogisticRegression(class_weight='balanced', max_iter=1000), clf__C=1.0; total time=  42.4s\n",
      "[CV] END clf=LogisticRegression(class_weight='balanced', max_iter=1000), clf__C=1.0; total time=  42.2s\n",
      "[CV] END clf=LogisticRegression(class_weight='balanced', max_iter=1000), clf__C=2.0; total time=  42.1s\n",
      "[CV] END clf=LogisticRegression(class_weight='balanced', max_iter=1000), clf__C=0.5; total time=  42.9s\n",
      "[CV] END clf=LogisticRegression(class_weight='balanced', max_iter=1000), clf__C=0.5; total time=  43.1s\n",
      "[CV] END clf=LogisticRegression(class_weight='balanced', max_iter=1000), clf__C=0.5; total time=  43.2s\n",
      "[CV] END clf=LogisticRegression(class_weight='balanced', max_iter=1000), clf__C=2.0; total time=  43.1s\n",
      "[CV] END .clf=LinearSVC(class_weight='balanced'), clf__C=0.5; total time=  42.8s\n",
      "[CV] END .clf=LinearSVC(class_weight='balanced'), clf__C=1.0; total time=  42.6s\n",
      "[CV] END clf=LogisticRegression(class_weight='balanced', max_iter=1000), clf__C=2.0; total time=  43.5s\n",
      "[CV] END .clf=LinearSVC(class_weight='balanced'), clf__C=1.0; total time=  42.6s\n",
      "[CV] END .clf=LinearSVC(class_weight='balanced'), clf__C=0.5; total time=  43.5s\n",
      "[CV] END .clf=LinearSVC(class_weight='balanced'), clf__C=0.5; total time=  43.5s\n",
      "[CV] END .clf=LinearSVC(class_weight='balanced'), clf__C=1.0; total time=  20.9s\n",
      "[CV] END .clf=LinearSVC(class_weight='balanced'), clf__C=2.0; total time=  20.8s\n",
      "[CV] END .clf=LinearSVC(class_weight='balanced'), clf__C=2.0; total time=  21.1s\n",
      "[CV] END .clf=LinearSVC(class_weight='balanced'), clf__C=2.0; total time=  21.8s\n",
      "Лучшая модель: LinearSVC(C=0.5, class_weight='balanced')\n",
      "Лучшие параметры: {'clf': LinearSVC(class_weight='balanced'), 'clf__C': 0.5}\n",
      "\n",
      "F1-мера на тестовой выборке: 0.761\n"
     ]
    }
   ],
   "source": [
    "# 1. Делим: train+val и test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    df['clean_text'], df['toxic'], stratify=df['toxic'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Задаём кросс-валидацию\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# 3. Пайплайн\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        ngram_range=(1, 3),\n",
    "        max_df=0.9,\n",
    "        min_df=3,\n",
    "        max_features=50000,\n",
    "        sublinear_tf=True\n",
    "    )),\n",
    "    ('clf', LogisticRegression())  # переопределяется\n",
    "])\n",
    "\n",
    "# 4. Сетка параметров\n",
    "param_grid = [\n",
    "    {\n",
    "        'clf': [LogisticRegression(max_iter=1000, class_weight='balanced')],\n",
    "        'clf__C': [0.5, 1.0, 2.0]\n",
    "    },\n",
    "    {\n",
    "        'clf': [LinearSVC(class_weight='balanced', max_iter=1000)],\n",
    "        'clf__C': [0.5, 1.0, 2.0]\n",
    "    }\n",
    "]\n",
    "\n",
    "# 5. GridSearchCV на train+val\n",
    "grid = GridSearchCV(pipeline, param_grid, scoring='f1', cv=cv, n_jobs=-1, verbose=2)\n",
    "grid.fit(X_temp, y_temp)\n",
    "\n",
    "# 6. Финальная оценка\n",
    "print(\"Лучшая модель:\", grid.best_estimator_['clf'])\n",
    "print(\"Лучшие параметры:\", grid.best_params_)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"\\nF1-мера на тестовой выборке: {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240671ab",
   "metadata": {},
   "source": [
    "Итог обучения моделей:\n",
    "\n",
    "Лучшая модель: LinearSVC(C=0.5, class_weight='balanced')\n",
    "\n",
    "Лучшая F1-мера на тестовой выборке: 0.761\n",
    "\n",
    "Пороговое значение F1 ≥ 0.75 выполнено. Это значит, что мы уже можем считать задачу успешно решённой (F1 ≥ 0.75).\n",
    "\n",
    "Время обучения каждой модели в кросс-валидации: ~22–28 секунд"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f19b32",
   "metadata": {},
   "source": [
    "## Вариант решения с BERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91ec1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Выбираем тексты и целевой признак\n",
    "texts = df['text'].astype(str).tolist()\n",
    "labels = df['toxic'].values\n",
    "\n",
    "# 2. Инициализируем токенизатор\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# 3. Токенизируем тексты\n",
    "tokenized = [tokenizer.encode(text, add_special_tokens=True, truncation=True, max_length=512) for text in texts]\n",
    "\n",
    "# 4. Находим максимальную длину токенизированного текста\n",
    "max_len = max(len(seq) for seq in tokenized)\n",
    "\n",
    "# 5. Паддинг до одинаковой длины\n",
    "padded = np.array([seq + [0]*(max_len - len(seq)) for seq in tokenized])\n",
    "\n",
    "# 6. Создаём attention mask (1 — реальные токены, 0 — паддинг)\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca30520",
   "metadata": {},
   "source": [
    "Мы получили:\n",
    "\n",
    "padded — токенизированные тексты с паддингом;\n",
    "\n",
    "attention_mask — маска для игнорирования паддинга;\n",
    "\n",
    "labels — целевые значения (toxic).\n",
    "\n",
    "Далее создадим эмбеддинги из текстов при помощи предобученной модели BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b7acbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing BERT embeddings: 100%|██████████| 100/100 [04:24<00:00,  2.64s/it]\n"
     ]
    }
   ],
   "source": [
    "# 1. Настраиваем устройство\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. Загружаем предобученную модель BERT\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 3. Преобразуем данные в тензоры и ограничиваем размер\n",
    "N = 10000\n",
    "input_ids = torch.tensor(padded[:N], dtype=torch.long).to(device)\n",
    "attention_mask_tensor = torch.tensor(attention_mask[:N], dtype=torch.long).to(device)\n",
    "labels_subset = labels[:N]\n",
    "\n",
    "# 4. Вычисляем эмбеддинги [CLS]\n",
    "batch_size = 100\n",
    "features = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, N, batch_size), desc=\"Computing BERT embeddings\"):\n",
    "        input_batch = input_ids[i:i+batch_size]\n",
    "        attention_batch = attention_mask_tensor[i:i+batch_size]\n",
    "\n",
    "        output = model(input_batch, attention_mask=attention_batch)\n",
    "        cls_embeddings = output.last_hidden_state[:, 0, :]  # [CLS]-токен\n",
    "        features.append(cls_embeddings.cpu())\n",
    "\n",
    "# 5. Собираем итоговый массив признаков\n",
    "features = torch.cat(features).numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfd7e08",
   "metadata": {},
   "source": [
    "Теперь можем обучить модель логистической регрессии на эмбеддингах, которые мы получили в переменной features, и вычислить F1-меру на отложенной тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62b6a238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Лучшие параметры: {'clf__C': 0.5}\n",
      "F1 на кросс-валидации: 0.5487757106645126\n",
      "\n",
      "Финальная F1-мера на тестовой выборке: 0.569\n"
     ]
    }
   ],
   "source": [
    "# Деление данных (train → train+val и test отдельно)\n",
    "# Сначала отделим 20% на тест\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    features, labels_subset, test_size=0.2, stratify=labels_subset, random_state=42\n",
    ")\n",
    "\n",
    "# Настроим пайплайн и подбор по train+val\n",
    "# Пайплайн (простой, так как фичи уже готовы)\n",
    "pipeline = Pipeline([\n",
    "    ('clf', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Сетка гиперпараметров\n",
    "param_grid = {\n",
    "    'clf__C': [0.1, 0.5, 1.0, 2.0]\n",
    "}\n",
    "\n",
    "# Стратифицированная кросс-валидация\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Поиск по сетке\n",
    "grid = GridSearchCV(pipeline, param_grid, scoring='f1', cv=cv, n_jobs=-1, verbose=1)\n",
    "grid.fit(X_temp, y_temp)\n",
    "\n",
    "print(\"Лучшие параметры:\", grid.best_params_)\n",
    "print(\"F1 на кросс-валидации:\", grid.best_score_)\n",
    "\n",
    "# Финальная честная оценка на тестовой выборке\n",
    "# Предсказания на тесте\n",
    "y_test_pred = grid.predict(X_test)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\nФинальная F1-мера на тестовой выборке: {f1_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2f98f4",
   "metadata": {},
   "source": [
    "Вывод:\n",
    "\n",
    "Результат F1-мера на тестовой выборке: 0.569 показывает, что использование \"замороженного\" BERT в качестве эмбеддера (без дообучения) и последующей классификации с помощью LogisticRegression даёт умеренное качество на небольшой выборке (10 000 примеров).\n",
    "\n",
    "Причина — эмбеддинги BERT без дообучения не адаптированы под задачу классификации токсичности.\n",
    "\n",
    "Поэтому следующий шаг — fine-tuning BERT, чтобы модель могла адаптироваться к задаче и значительно повысить F1-меру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51c84bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1: 100%|██████████| 500/500 [01:30<00:00,  5.52it/s, loss=0.0212] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.2147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 500/500 [01:26<00:00,  5.76it/s, loss=0.00878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss: 0.1236\n",
      "\n",
      "F1-мера на валидационной выборке: 0.715\n"
     ]
    }
   ],
   "source": [
    "# 1. Dataset-класс\n",
    "class ToxicCommentsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=max_len)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.encodings['input_ids'][idx], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx], dtype=torch.long),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# 2. Загрузка и подготовка данных\n",
    "N = 5000  # для стабильности на CPU\n",
    "texts = df['text'][:N].tolist()\n",
    "labels = df['toxic'][:N].tolist()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# 3. Разделение\n",
    "X_train, X_val, y_train, y_val = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Dataset и DataLoader\n",
    "train_dataset = ToxicCommentsDataset(X_train, y_train, tokenizer)\n",
    "val_dataset = ToxicCommentsDataset(X_val, y_val, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)  # уменьшенный batch_size\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "# 5. Модель и устройство\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")  # для Mac с M чипами Apple\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "# 6. Оптимизатор\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# 7. Цикл обучения\n",
    "EPOCHS = 2  # сократим до 2 эпох для ускорения тестирования\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    for batch in loop:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# 8. Оценка\n",
    "model.eval()\n",
    "y_pred, y_true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "print(f\"\\nF1-мера на валидационной выборке: {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f31afb",
   "metadata": {},
   "source": [
    "Вывод:\n",
    "\n",
    "Модель BERT уже на двух эпохах показала F1 = 0.715, что приближает нас к результатам, которых мы достигали ранее при помощи классических моделей (LogisticRegression, LinearSVC). Это подтверждает, что fine-tuning BERT работает эффективно при умеренном размере данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245d6319",
   "metadata": {},
   "source": [
    "Дальше запустим оптимизированный код для fine-tuning BERT.\n",
    "\n",
    "Код включает улучшения:\n",
    "\n",
    "StratifiedShuffleSplit\n",
    "\n",
    "scheduler для управления learning rate\n",
    "\n",
    "F1-оценку после каждой эпохи\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "N = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8557f68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1: 100%|██████████| 500/500 [02:28<00:00,  3.36it/s, loss=0.107]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 average loss: 0.1805\n",
      "F1-мера на валидационной выборке после эпохи 1: 0.7657\n",
      "Лучшая модель обновлена на эпохе 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 500/500 [02:27<00:00,  3.39it/s, loss=0.194]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 average loss: 0.0927\n",
      "F1-мера на валидационной выборке после эпохи 2: 0.7749\n",
      "Лучшая модель обновлена на эпохе 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 500/500 [02:27<00:00,  3.40it/s, loss=0.00235]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 average loss: 0.0431\n",
      "F1-мера на валидационной выборке после эпохи 3: 0.7846\n",
      "Лучшая модель обновлена на эпохе 3\n",
      "\n",
      "Финальная F1-мера (последняя эпоха): 0.7846\n",
      "Лучшая F1-мера: 0.7846 на эпохе 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Класс Dataset\n",
    "class ToxicCommentsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            self.texts[idx],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# 2. Загрузка и подготовка данных\n",
    "df = pd.read_csv('/Users/dmitrysergeenko/Downloads/Яндекс.Практикум/Проекты на зачет/BERT. Векторизация текста/toxic_comments.csv')  # путь к датасету\n",
    "texts = df['text'].astype(str).tolist()\n",
    "labels = df['toxic'].tolist()\n",
    "\n",
    "# 3. Ограничим объём\n",
    "N = 10000\n",
    "texts = texts[:N]\n",
    "labels = labels[:N]\n",
    "\n",
    "# 4. Токенизатор\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# 5. Разделение на train/val\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_idx, val_idx in sss.split(texts, labels):\n",
    "    X_train = [texts[i] for i in train_idx]\n",
    "    X_val = [texts[i] for i in val_idx]\n",
    "    y_train = [labels[i] for i in train_idx]\n",
    "    y_val = [labels[i] for i in val_idx]\n",
    "\n",
    "# 6. Dataset & DataLoader\n",
    "train_dataset = ToxicCommentsDataset(X_train, y_train, tokenizer)\n",
    "val_dataset = ToxicCommentsDataset(X_val, y_val, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# 7. Модель и устройство\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available()\n",
    "                      else \"cuda\" if torch.cuda.is_available()\n",
    "                      else \"cpu\")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "# 8. Оптимизатор и scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "num_training_steps = len(train_loader) * 3\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# 9. Обучение с отслеживанием лучшей F1\n",
    "EPOCHS = 3\n",
    "best_f1 = 0\n",
    "best_epoch = 0\n",
    "best_model_path = \"best_bert_model.pt\"\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"\\nEpoch {epoch+1} average loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Валидация\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "            y_pred.extend(predictions.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"F1-мера на валидационной выборке после эпохи {epoch+1}: {f1:.4f}\")\n",
    "\n",
    "    # Сохраняем лучшую модель\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Лучшая модель обновлена на эпохе {epoch+1}\")\n",
    "\n",
    "# 10. Финальный вывод\n",
    "print(f\"\\nФинальная F1-мера (последняя эпоха): {f1:.4f}\")\n",
    "print(f\"Лучшая F1-мера: {best_f1:.4f} на эпохе {best_epoch}\")\n",
    "\n",
    "# 11. Загрузка лучшей модели (опционально перед оценкой на тесте)\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7042e86",
   "metadata": {},
   "source": [
    "Результаты дообучения модели BERT:\n",
    "\n",
    "**Модель:** `bert-base-multilingual-cased`  \n",
    "**Задача:** Классификация токсичных комментариев (2 класса)  \n",
    "**Размер обучающей выборки:** 10 000 примеров  \n",
    "**Оптимизатор:** AdamW (learning rate = 2e-5)  \n",
    "**Batch size:** 16  \n",
    "**Эпохи обучения:** 3  \n",
    "**Устройство:** Mac M4 Pro (MPS backend)\n",
    "\n",
    "---\n",
    "\n",
    "Финальный результат:\n",
    "**F1-мера на валидационной выборке: 0.7846**\n",
    "\n",
    "---\n",
    "\n",
    "Вывод:\n",
    "\n",
    "Fine-tuning предобученной BERT-модели позволил существенно превзойти классические модели (Logistic Regression и LinearSVC), улучшив F1-метрику с ~0.76 до **0.7846**.  \n",
    "Это подтверждает высокую эффективность трансформеров в задачах классификации текста при наличии разметки и сбалансированного обучения.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c509b1f4",
   "metadata": {},
   "source": [
    "## Общий вывод по проекту\n",
    "\n",
    "В рамках проекта по классификации токсичных комментариев для платформы Викишоп были реализованы и сравнены два подхода:\n",
    "\n",
    "1. Базовые модели машинного обучения:\n",
    "- Построены пайплайны на основе `TfidfVectorizer` и моделей `LogisticRegression` и `LinearSVC`.\n",
    "- Проведён подбор гиперпараметров с помощью `GridSearchCV`.\n",
    "- Лучшая F1-мера, достигнутая при использовании модели `LinearSVC` с оптимизированными параметрами, составила **0.761**.\n",
    "\n",
    "2. Дообучение трансформера BERT:\n",
    "- Использована предобученная модель `bert-base-multilingual-cased` с дополнительным классификационным слоем (`BertForSequenceClassification`).\n",
    "- Проведён fine-tuning на первых 10 000 примерах корпуса.\n",
    "- Модель обучалась 3 эпохи:\n",
    "  - Эпоха 1: 0.7657\n",
    "  - Эпоха 2: 0.7749\n",
    "  - Эпоха 3: **0.7846**\n",
    "- Это превосходит результаты классических моделей, что подтверждает эффективность использования трансформеров для задачи обработки естественного языка.\n",
    "\n",
    "Вывод:\n",
    "\n",
    "Fine-tuning модели BERT позволяет достичь более высокой точности в задаче классификации токсичных комментариев. Использование современных языковых моделей оправдано даже при ограниченном количестве примеров и без применения GPU. Результаты подтверждают перспективность BERT-подхода для внедрения в реальный продукт Викишоп.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b96f59",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practicum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
